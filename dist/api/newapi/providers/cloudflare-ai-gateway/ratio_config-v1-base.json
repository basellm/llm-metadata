{
  "data": {
    "cache_ratio": {},
    "completion_ratio": {
      "anthropic/claude-3-opus": 5,
      "anthropic/claude-3-sonnet": 5,
      "anthropic/claude-3.5-sonnet": 5,
      "anthropic/claude-haiku-4-5": 5,
      "anthropic/claude-haiku-4.5": 5,
      "anthropic/claude-opus-4": 5,
      "anthropic/claude-opus-4-1": 5,
      "anthropic/claude-opus-4-5": 5,
      "anthropic/claude-opus-4.1": 5,
      "anthropic/claude-opus-4.5": 5,
      "anthropic/claude-sonnet-4": 5,
      "anthropic/claude-sonnet-4-5": 5,
      "anthropic/claude-sonnet-4.5": 5,
      "openai/gpt-4": 2,
      "openai/gpt-4-turbo": 3,
      "openai/gpt-4o": 4,
      "openai/gpt-5.1": 8,
      "openai/gpt-5.1-codex": 8,
      "openai/o1": 4,
      "openai/o1-mini": 4,
      "openai/o1-preview": 4,
      "openai/o3": 4,
      "openai/o3-mini": 4,
      "openai/o3-pro": 4,
      "openai/o4-mini": 4,
      "replicate/deepseek-ai/deepseek-r1": 1,
      "replicate/meta/meta-llama-3.1-405b-instruct": 1,
      "replicate/replicate-internal/llama-405b-instruct-vllm": 1
    },
    "model_price": {},
    "model_ratio": {
      "anthropic/claude-3-opus": 7.5,
      "anthropic/claude-3-sonnet": 1.5,
      "anthropic/claude-3.5-sonnet": 1.5,
      "anthropic/claude-haiku-4-5": 0.5,
      "anthropic/claude-haiku-4.5": 0.5,
      "anthropic/claude-opus-4": 7.5,
      "anthropic/claude-opus-4-1": 7.5,
      "anthropic/claude-opus-4-5": 2.5,
      "anthropic/claude-opus-4.1": 7.5,
      "anthropic/claude-opus-4.5": 2.5,
      "anthropic/claude-sonnet-4": 1.5,
      "anthropic/claude-sonnet-4-5": 1.5,
      "anthropic/claude-sonnet-4.5": 1.5,
      "openai/gpt-4": 15,
      "openai/gpt-4-turbo": 5,
      "openai/gpt-4o": 1.25,
      "openai/gpt-5.1": 0.625,
      "openai/gpt-5.1-codex": 0.625,
      "openai/o1": 7.5,
      "openai/o1-mini": 0.55,
      "openai/o1-preview": 7.5,
      "openai/o3": 1,
      "openai/o3-mini": 0.55,
      "openai/o3-pro": 10,
      "openai/o4-mini": 0.55,
      "replicate/deepseek-ai/deepseek-r1": 5,
      "replicate/meta/meta-llama-3.1-405b-instruct": 4.75,
      "replicate/replicate-internal/llama-405b-instruct-vllm": 4.75
    }
  },
  "message": "",
  "success": true
}